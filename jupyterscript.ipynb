{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "## SNP Pre-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I aim to do with this R script is to clean and filter all of the raw information previously given to me so that I can use it later on for more important analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, here are the packages and libraries I had to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘data.table’\n",
      "\n",
      "The following object is masked _by_ ‘.GlobalEnv’:\n",
      "\n",
      "    .N\n",
      "\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:data.table’:\n",
      "\n",
      "    between, first, last\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Packages and libraries\n",
    "# install.packages(c(\"data.table\", \"dplyr\"))\n",
    "library(data.table)\n",
    "library(dplyr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we enter the actual coding session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We open the raw PHS(PopHumanScan) table\n",
    "PHS.table <- read.table('Desktop/AleixCanalda/tableWOmeta.tab', header=T, sep=\"\\t\")\n",
    "\n",
    "#We have a look at the dimensions of the table\n",
    "dim(PHS.table)\n",
    "\n",
    "# We select the regions that show us a signal for iHS or XPEHH (there should be 487 positions)\n",
    "significant <- grep('iHS:|XPEHH:', PHS.table$statPop)\n",
    "\n",
    "#Now we only use the columns we're interested in\n",
    "useful.table <- PHS.table %>% select(GeneID, Type, chr, start, end, statPop)\n",
    "#From all the rows we only get the ones that are significant \n",
    "useful.table <- useful.table[significant,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this has been done, we want to create a new column with all of the populations represented in those regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create a new column where we'll write only the populations\n",
    "useful.table$Pop <- NA\n",
    "#What we want to do now is from the Statpop column only get the population, and not iHS or XPEHH\n",
    "for (popupopu in 1:nrow(useful.table)) {\n",
    "  #this next step is to make sure we're doing everything correctly\n",
    "  #We separate all of the statistics with their populations (which are separated by a comma),\n",
    "    #we use \"as.character\" to let R know that we're using characters\n",
    "  splitsplit <- strsplit(as.character(useful.table[popupopu,\"statPop\"]),\",\")\n",
    "  #From those stats, we only need iHS and XPEHH, and we use unlist to create a vector from the \n",
    "    #list created with split\n",
    "  good <- grep('iHS:|XPEHH:', unlist(splitsplit))\n",
    "  #Since we only want the populations, we erase the stats\n",
    "  populations <- gsub(\"iHS:|XPEHH:\",\"\",unlist(splitsplit)[good])\n",
    "  #We paste the populations on the new column, separated by a comma\n",
    "  useful.table$Pop[popupopu]<- paste(populations, collapse=\",\")\n",
    "}\n",
    "#We save the table so that we can use it later on (that way we don't have to repeat this process constantly)\n",
    "write.table(useful.table, file=\"/home/aleixcanalda/Desktop/AleixCanalda/goodstats.txt\",\n",
    "            append = FALSE, quote = F, sep = \"\\t\",\n",
    "            col.names = TRUE, row.names = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our table, we have to get from the iHS results all the SNPs that are found in these regions and that are statistically significant (extremevalue==1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly we create a loop to go through every single chromosome\n",
    "for (c in 1:22) {\n",
    "  chromosome <- paste0(\"chr\",c)\n",
    "  # We create a subset of all the regions in PHS of that chromosome\n",
    "  regions.per.chr <- useful.table %>% filter(chr==chromosome)\n",
    "  \n",
    "  # New loop of each region of PHS for the specific chromosome, one by one\n",
    "  for(region in 1:nrow(regions.per.chr)){\n",
    "    current.region <- regions.per.chr[region,]\n",
    "    # Now we create a loop to go through all of the populations use a txt file with all of the populations\n",
    "    for(pop in list.populations) {\n",
    "      # At first we must access the file where we can finde the iHS information of the SNPs\n",
    "      prova.chr.pop <- read.table(paste0('Desktop/AleixCanalda/ihs.output/', chromosome, \"/\", chromosome, pop,\n",
    "                                         \".ihs.out.100bins.norm\"), header=T, sep=\"\\t\")\n",
    "      #We select those SNPs that are statistically important (extremevalue=1) and those that are found inside \n",
    "        #the regions that present LD\n",
    "      posicionschr.snp <- prova.chr.pop[prova.chr.pop$extremevalue==1 & \n",
    "                                          prova.chr.pop$physicalPos>current.region$start & \n",
    "                                          prova.chr.pop$physicalPos<current.region$end, 2]\n",
    "      #if we can indeed find SNPs in such regions, we will save them in a dataframe and paste it in the table \n",
    "        #that we created before\n",
    "      if(length(posicionschr.snp)>0){\n",
    "        region.info <- data.frame(current.region$GeneID, current.region$Type, current.region$chr,\n",
    "                                  current.region$start, posicionschr.snp, pop)\n",
    "        finalsnptable <- rbind(finalsnptable, region.info)\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "#Lastly, we must name all of the columns accordingly\n",
    "colnames(finalsnptable) <- c(\"GeneID\",\"Type\",\"chr\",\"Region start\",\"SNP Position\",\"Population\")\n",
    "write.table(finalsnptable, file=\"/home/aleixcanalda/Desktop/AleixCanalda/finalsbptable.txt\",\n",
    "            append = FALSE, quote = F, sep = \"\\t\",\n",
    "            col.names = TRUE, row.names = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to know which is each SNP's rsID to use it later on in ensembl.\n",
    "To do that, we need to download biomaRt.\n",
    "The next script explains how to do so, however, snpmart works at a very slow rate and taking in account the amount of information and SNPs that I have, I decided to use an online tool named Kaviar Genomics where you obtain each rsID by simply giving it the exact location and choosing the Human Genome we're using(GRCh37 in our case) and the type of variation we're looking for (SNVs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source(\"https://bioconductor.org/biocLite.R\")\n",
    "BiocInstaller::biocLite(c(\"RMySQL\",\"GenomicFeatures\",\"VariantAnnotation\",\"ensemblVEP\"))\n",
    "install.packages(c(\"libmariadb-client-lgpl-dev\"))\n",
    "BiocManager::install(\"biomaRt\")\n",
    "\n",
    "library(biomaRt)\n",
    "\n",
    "# require(biomaRt)\n",
    "head(listMarts())\n",
    "mart  <- useMart(biomart=\"ensembl\", \n",
    "                 dataset=\"hsapiens_gene_ensembl\")\n",
    "\n",
    "listAttributes(mart)[1:10,]\n",
    "listFilters(snpmart)[1:10,]\n",
    "\n",
    "snpmart <- useMart(biomart = \"ENSEMBL_MART_SNP\", dataset = \"hsapiens_snp\")\n",
    "mart <- useMart(biomart = \"ensembl\", dataset = \"hsapiens_gene_ensembl\")\n",
    "\n",
    "#But we're not using the latest version of the human genome, so we must specify that ours is GRCh37 \n",
    "finalsnptable <- read.table(\"Desktop/AleixCanalda/finalsbptable.txt\",header=T,sep=\"\\t\")\n",
    "\n",
    "grch37 = useMart(biomart=\"ENSEMBL_MART_SNP\", dataset = \"hsapiens_snp\", host=\"grch37.ensembl.org\",\n",
    "                 path=\"/biomart/martservice\")\n",
    "listDatasets(grch37)\n",
    "listAttributes(grch37)\n",
    "listFilters(grch37)\n",
    "\n",
    "results <- data.frame()\n",
    " #Initialise storage vector\n",
    "\n",
    " for (snp in 1:nrow(finalsnptable)) {  \n",
    "   chrom <- gsub(pattern = 'chr', replacement = '', x = finalsnptable[snp, 3]) \n",
    "   # Remove 'chr' for searching\n",
    "    #we're looking for the allele and the refsnp_id by giving it the start and end of the SNP\n",
    "    temp <- getBM(attributes = c('refsnp_id','allele'), \n",
    "                  filters = c('chr_name','start','end'), \n",
    "                  values = list(chrom,finalsnptable$`SNP Position`[snp],finalsnptable$`SNP Position`[snp]),\n",
    "                  mart = grch37)\n",
    "    if (nrow(temp)!=0){\n",
    "      info.snp <- data.frame(chrom, finalsnptable$`SNP Position`[snp], temp)\n",
    "      }\n",
    "    else{\n",
    "      info.snp <- c(chrom, finalsnptable$`SNP Position`[snp], NA, NA)\n",
    "    }\n",
    "    results <- rbind(results,info.snp)\n",
    "  }\n",
    "\n",
    "write.table(results, file=\"/home/aleixcanalda/Desktop/AleixCanalda/snpvepbiomart.txt\",\n",
    "            append = FALSE, quote = F, sep = \"\\t\",\n",
    "            col.names = TRUE, row.names = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the Kaviar Genomics service, we need to create a file with the position of all the available and significant SNPs in this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use VEP first we need to create a new document with the information of the SNP's position which is what we'll use.\n",
    "snpvep <- data.frame()\n",
    "\n",
    "for (vep in 1:nrow(finalsnptable)) {\n",
    "  chrom <- gsub(pattern = 'chr', replacement = '', x = finalsnptable$chr[vep])\n",
    "  snpinfo <- data.frame(paste0(chrom,\":\",finalsnptable$`SNP Position`[vep]))\n",
    "  snpvep <- rbind(snpvep,snpinfo)\n",
    "}\n",
    "write.table(snpvep, file=\"/home/aleixcanalda/Desktop/AleixCanalda/snpvep2.txt\",\n",
    "            append = FALSE, quote = F, sep = \"\\t\",\n",
    "            col.names = TRUE, row.names = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can use the Kaviar Genomic Variant Database where we can find all of the rsIDs of the SNPs that we'll need to use them for VEP on the terminal\n",
    "#But before we can use VEP we have to create a file where the only information is the rsIDs\n",
    "rsidtable <- fread(\"/home/aleixcanalda/Desktop/AleixCanalda/vcfsnp.txt\",header = T, sep = \"\\t\")\n",
    "rsids <- data.frame(rsidtable$ID)\n",
    "write.table(rsids, file=\"/home/aleixcanalda/Desktop/AleixCanalda/rsids.txt\",\n",
    "            append = FALSE, quote = F, sep = \"\\t\",\n",
    "            col.names = TRUE, row.names = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant Effect Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the rsIDs of each SNP we can use VEP to find out what consequence each SNP has and how important it may be in a genomic adaptive sense. VEP can be used online when one has few information but that is not my case, so I need to download the whole VEP package to use it on the terminal. Nevertheless, the package contains an enormous amount of information and needs a lot of internet connection, and that is not possible with my computer, but we found a solution. I have been added to the investigation group's Server so that I can use the internet and run some commands there. \n",
    "\n",
    "To install VEP, which is no easy task, I firstly needed to install BioConda in order to use Conda, which, by definition, is \"an open source package management system and environment management system that runs on Windows, macOS and Linux. Conda quickly installs, runs and updates packages and their dependencies. Conda easily creates, saves, loads and switches between environments on your local computer. It was created for Python programs, but it can package and distribute software for any language.\"\n",
    "Therefore, by using Conda I already had a few packages installed. \n",
    "\n",
    "Once the human genome information for VEP was downloaded, and by sending the rsIDs file into the remote Server, I was able to obtain all of the necessary information regarding the impact of the SNP, by using this line in bash language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bash\n",
    "./vep --cache --port 3337 -i /home/acanalda/Data/rsids.txt -o /home/acanalda/Data/vepresults.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all of the information on VEP, we want to determine which SNP has the most effect on the genome and which has a less effect, however can¡t reassure that, for example, an intergenic variant has a lesser effect than an intronic variant, since regulatory sequences may be involved (which is why later on I determined the Regulome score for each SNP). \n",
    "\n",
    "I decided to create an order of worse consequence to a more benign consequence, according to information published on Ensembl saying which consequences had more impact: high, moderate, low or modifier. I decided to differentiate each consequence inside each group using my own criteria (revised by my tutor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Firstly we read the table with the VEP results\n",
    "vepresults <- fread(\"/home/aleixcanalda/Desktop/AleixCanalda/VEP/vepresults.txt\", header=T)\n",
    "vepresults$NumConsequence <- NA\n",
    "vepresults$MaxNumConsequence <- NA\n",
    "\n",
    "vepresults[, `NumConsequence`:=as.character(`NumConsequence`)]\n",
    "vepresults[, `MaxNumConsequence`:=as.character(`MaxNumConsequence`)]\n",
    "#Secondly we read the text file with all of the rsIDs\n",
    "ids <- readLines(\"/home/aleixcanalda/Desktop/AleixCanalda/rsids.txt\")\n",
    "\n",
    "#we create the table where we'll store all of the SNPs with their worst consequence\n",
    "finalconseqnumbertable <- data.frame()\n",
    "\n",
    "#we use a hierarchy to determine which effect is worser than the next one, being a stop gained the worst effect\n",
    "allconseq <- c(\"stop_gained\",\"stop_lost\",\"start_lost\",\"splice_acceptor_variant\",\"splice_donor_variant\",\n",
    "               \"missense_variant\",\"splice_region_variant\",\"incomplete_terminal_codon_variant\",\"stop_retained_variant\",\n",
    "               \"synonymous_variant\",\"coding_sequence_variant\",\"5_prime_UTR_variant\",\"3_prime_UTR_variant\",\n",
    "               \"mature_miRNA_variant\",\"NMD_transcript_variant\",\"non_coding_transcript_exon_variant\",\n",
    "               \"non_coding_transcript_variant\",\"intron_variant\",\"upstream_gene_variant\",\"downstream_gene_variant\",\n",
    "               \"intergenic_variant\")\n",
    "#then we create a general table where we assign each consequence a number, 1 being the worst consequence and 21 \n",
    "#the most benign\n",
    "conseqnum <- data.frame(Consequence=allconseq,Impact=c(1:21))\n",
    "\n",
    "#we create a loop where we read each rsID one by one\n",
    "for (rsid in ids) {\n",
    "  print(paste(\"-->\", rsid, sep=\" \"))\n",
    "  #from the rsID we're reading now we get all of its rows and we only look at the \"Consequence\" column.\n",
    "    #All of the rows whose consequence is repeated is put into one single consequence using \"unique\"\n",
    "  vector <- unlist(unique(vepresults[vepresults$`#Uploaded_variation`==rsid,7]))\n",
    "  #we then look at each consequence to see if there are more than one in one line joined by a ',', so we can\n",
    "    #separate them\n",
    "  for (aiai in vector) {\n",
    "    if (grepl(\",\",aiai) == TRUE) {\n",
    "      new <- unlist(strsplit(aiai, \",\"))\n",
    "      \n",
    "      vector <-append(vector,new)\n",
    "      vector = vector[!(vector %in% aiai)]\n",
    "      vector <- unique(vector)\n",
    "    }\n",
    "    else {next}\n",
    "  }\n",
    "  #for each consequence, we write down its numerical impact\n",
    "  for (hello in 1:length(vector)) {\n",
    "    vector[hello] <- conseqnum[conseqnum$Consequence == vector[hello],\"Impact\"]\n",
    "  }\n",
    "  #now we save every row with this snp, but we only need one snp, since all of the consequences will be \n",
    "    #written down anyway and we have another column for the maximum consequence\n",
    "  wewe <- vepresults[vepresults$`#Uploaded_variation`==rsid,]\n",
    "  wewe <- wewe[1,]\n",
    "  wewe[,15] <- paste(vector, collapse = \",\")\n",
    "  wewe[,16] <- vector[which.min(vector)]\n",
    "  finalconseqnumbertable <- rbind(finalconseqnumbertable,wewe)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalconseqnumbertable <- fread(\"/home/aleixcanalda/Desktop/AleixCanalda/VEP/.txt\", header=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RegulomeDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, our aim was to find out what effect each SNP had on regulatory region, if they found themselves in one, since they might not seem to have a big effect according to VEP, but regulatory regions are very important and must have a closer look. The scores for such regions range from 1a to 7, 1a being a SNP which presents a great effect on a regulatory region, and 7 not presenting a significant or no effect at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages and libraries\n",
    "install.packages(\"data.table\")\n",
    "install.packages(\"haploR\", dependencies = TRUE)\n",
    "library(data.table)\n",
    "library(haploR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we must read all of the rsIDs that we've used until now\n",
    "dbsnp <- readLines(\"/home/aleixcanalda/Desktop/AleixCanalda/rsids.txt\")\n",
    "#now we bring our latest table so that we can add the new regulome information\n",
    "finalconseqnumbertable <- fread(\"/home/aleixcanalda/Desktop/AleixCanalda/VEP/finalconseqtable.txt\",header = T,\n",
    "                                sep = \"\\t\")\n",
    "#we must create a regulome column where we'll write all of the scores for each SNP, the lowest number being a\n",
    "#SNP highly related to any aspect of genome regulation\n",
    "finalconseqnumbertable$Regulomescore <- NA\n",
    "#we must make the whole column a character because we have both numbers and letters in our scores\n",
    "finalconseqnumbertable[, `Regulomescore`:=as.character(`Regulomescore`)]\n",
    "\n",
    "#we then create a loop where we go through each SNP to get their score\n",
    "for (snp in dbsnp) {\n",
    "  print(paste(\"-->\", snp, sep=\" \"))\n",
    "  #using this command we can access the database through R\n",
    "  x <- queryRegulome(snp)\n",
    "  #if we can't find a score for that SNP, it is probably unrelated to regulation or hasn't been looked at yet,\n",
    "    #so we move on to the next one\n",
    "  if (is.null(x$res.table$score)) {next}\n",
    "  #but if we do indeed find a information for the SNP we must retain it in the rightful column\n",
    "  else{\n",
    "    finalconseqnumbertable[finalconseqnumbertable$`#Uploaded_variation`==snp, \"Regulomescore\"] <- \n",
    "      as.character(x$res.table$score)\n",
    "  }\n",
    "}\n",
    "write.table(finalconseqnumbertable, file=\"/home/aleixcanalda/Desktop/AleixCanalda/VEP/finalconseqregulometable.txt\",\n",
    "            append = FALSE, quote = F, sep = \"\\t\",\n",
    "            col.names = TRUE, row.names = F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're interested in ranking the SNPs, like the consequences, we'll rank the regulome scores from 1 to 15, instead of 1a, 1b, 1c, ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalconseqnumbertable <- fread(\"/home/aleixcanalda/Desktop/AleixCanalda/VEP/finalconseqregulometable.txt\",header = T,\n",
    "                          sep = \"\\t\")\n",
    "finalconseqnumbertable$Regulomescore <- NA\n",
    "#we must make the whole column a character because we have both numbers and letters in our scores\n",
    "finalconseqnumbertable[, `Regulomescore`:=as.integer(`Regulomescore`)]\n",
    "\n",
    "finalconseqnumbertable[,17] <- finalconseqtable[,15]\n",
    "\n",
    "#to make our table even better we should separate the location column into chromosome and position since it's \n",
    "#generally more useful for handling data\n",
    "finalconseqnumbertable$Chromosome <- NA\n",
    "finalconseqnumbertable[, `Chromosome`:=as.character(`Chromosome`)]\n",
    "\n",
    "#to do so we create a loop that goes through every row and separates the location column\n",
    "for (chr in 1:nrow(finalconseqnumbertable)) {\n",
    "  vec <- unlist(strsplit(as.character(finalconseqnumbertable[chr,2]),\":\"))\n",
    "  finalconseqnumbertable[chr,18] <- vec[1]\n",
    "  finalconseqnumbertable[chr,2] <- vec[2]\n",
    "}\n",
    "finalconseqnumbertable <- finalconseqnumbertable[,c(1,18,2:17)]\n",
    "\n",
    "#now we must transform all of the regulome scores into numerical values in order to create a matrix for the heatmap\n",
    "allscores <- c(\"1a\",\"1b\",\"1c\",\"1d\",\"1e\",\"1f\",\"2a\",\"2b\",\"2c\",\"3a\",\"3b\",\"4\",\"5\",\"6\",\"7\")\n",
    "\n",
    "#as we did before with the consequences we create a data.frame with the scores\n",
    "conseqregscores <- data.frame(Scores=allscores,Importance=c(1:15))\n",
    "#we then create a loop going through each snp and each score\n",
    "for (regreg in 1:nrow(finalconseqnumbertable)) {\n",
    "  for (eachscore in allscores) {\n",
    "    #if the score is different from NA, then go through everything\n",
    "    if (!is.na(finalconseqnumbertable[regreg,18])) {\n",
    "      #if we have found our score, change into its numerical equivalent\n",
    "      if (finalconseqnumbertable[regreg,18] == eachscore) {\n",
    "        finalconseqnumbertable[regreg,18] <- conseqregscores[conseqregscores$Scores==eachscore,\"Importance\"]\n",
    "      }\n",
    "      #otherwise, go to the next score\n",
    "      else {next}\n",
    "      break\n",
    "    }\n",
    "    #if there is indeed an NA, go to the next snp\n",
    "    else {next}\n",
    "  }\n",
    "}\n",
    "\n",
    "write.table(finalconseqnumbertable, file=\"/home/aleixcanalda/Desktop/AleixCanalda/VEP/finalconseqnumbertable.txt\",\n",
    "            append = FALSE, quote = F, sep = \"\\t\",\n",
    "            col.names = TRUE, row.names = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of the information that we need regarding VEP and Regulome scores, we can create a graph to represent the information and see more clearly which SNPs seem to have a bigger effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages and libraries\n",
    "library(data.table)\n",
    "\n",
    "library(gplots)\n",
    "\n",
    "library(heatmap.plus)\n",
    "\n",
    "library(RColorBrewer)\n",
    "\n",
    "library(dplyr)\n",
    "\n",
    "library(gridExtra)\n",
    "\n",
    "library(ComplexHeatmap)\n",
    "\n",
    "library(circlize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need the following tables in order to produce the graph\n",
    "finalconseqnumbertable <- fread(\"/home/aleixcanalda/Desktop/AleixCanalda/VEP/finalconseqnumbertable.txt\",header = T,\n",
    "                                sep = \"\\t\")\n",
    "bigtable <- fread(\"/home/aleixcanalda/Desktop/AleixCanalda/goodstats.txt\",header = T, sep = \"\\t\") \n",
    "populations <- readLines(\"/home/aleixcanalda/Desktop/AleixCanalda/Populations.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to obtain a heatmap for every region with all of the SNPs inside that region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in order to create all of the graphs at once we must do so for every chromosome\n",
    "for (c in 1:22) {\n",
    "  chromosome <- paste0(\"chr\",c)\n",
    "  print(paste(\"-->\", chromosome, sep=\" \"))\n",
    "  #the heat maps are created by regions according to PopHumanScan, therefore from the previously rearranged final \n",
    "    #consequence table we'll grab the snps in each round which are of interest to us, for each region for each \n",
    "    #chromosome\n",
    "  #We create a subset of all the regions in PHS of that chromosome\n",
    "  regions.per.chr <- bigtable %>% filter(chr==chromosome)\n",
    "  for (region in 1:nrow(regions.per.chr)) {\n",
    "    print(paste(\"--> region \", region, sep=\" \"))\n",
    "    #we create a dataframe with which we'll create the desired heat map\n",
    "    inregion <- data.frame()\n",
    "    for (wowo in 1:nrow(finalconseqnumbertable)) {\n",
    "      #if the snp we're looking at now is inside the region and in the chr we're looking at now, we'll keep it\n",
    "      if (finalconseqnumbertable[wowo,3]>regions.per.chr[region,4] & finalconseqnumbertable[wowo,3]<\n",
    "          regions.per.chr[region,5]) {\n",
    "        lala <- finalconseqnumbertable[wowo,]\n",
    "        inregion <- rbind(inregion,lala)\n",
    "       \n",
    "      }\n",
    "    }\n",
    "    #to create the matrix, we're solely interested in representing the VEP and RegulomeDB results, but we'll \n",
    "      #also need the location to compare each snp with its population and its rsID to classify each SNP\n",
    "    if (length(inregion)==0) {next}\n",
    "    inregion <- inregion[,c(1,3,17:18)]\n",
    "    \n",
    "\n",
    "    #we'll go through every population to see if it presents the SNP\n",
    "    for (popu in 1:length(populations)) {\n",
    "      print(paste(\"-->\", populations[popu], sep=\" \"))\n",
    "      #first we load the whole list of snps for that population\n",
    "      prova.chr.pop <- fread(paste0('/home/aleixcanalda/Desktop/AleixCanalda/ihs.output/', chromosome,'/', chromosome,\n",
    "                                    populations[popu],\".ihs.out.100bins.norm\"), header=T, sep=\"\\t\")\n",
    "      #we create a dataframe where we'll save each snp whether its in the population or not(value of 0)\n",
    "      popihs <- data.frame()\n",
    "      for (snp in 1:nrow(inregion)) {\n",
    "        print(paste(\"--> snp \", snp, sep=\" \"))\n",
    "        \n",
    "        #then we get the exact position of our current snp\n",
    "        whatwhat <- unlist(inregion[snp,2])\n",
    "        #if our snp is found in the document with all the snps looking at the location, then we'll save the iHS \n",
    "          #value of that snp\n",
    "        if (is.element((inregion[snp,\"Location\"]),prova.chr.pop$physicalPos)){\n",
    "         popihs <- rbind(popihs,unlist(prova.chr.pop[prova.chr.pop$physicalPos == whatwhat,\"standarizediHS\"]))\n",
    "        }\n",
    "        #if the snp isnt in the file, simply write a 0 (it'll appear white on the heatmap)\n",
    "        else {popihs <- rbind(popihs,NA)}\n",
    "      }\n",
    "      #we'll name this dataframe with the population we're looking at now and we'll add it to the main heatmap \n",
    "        #dataframe\n",
    "      colnames(popihs) <- populations[popu]\n",
    "      inregion <- cbind(inregion,popihs)\n",
    "    }\n",
    "    #we want the rownames to be the rsIDs so we can identify each SNP later on\n",
    "    rnames <-  inregion[,\"#Uploaded_variation\"]\n",
    "    #once we've saved the rsIDs, we dont need them or their position anymore, so we only keep the rest\n",
    "    inregion <- inregion[,3:26]\n",
    "    rownames(inregion) <- unlist(rnames)\n",
    "    #heatmap only works mith a matrix so we must transform our data into a matrix\n",
    "    inregion <- data.matrix(inregion)\n",
    "    \n",
    "    eff <- inregion[,1:2]\n",
    "    ihsmap <- inregion[,3:24]\n",
    "    \n",
    "    #in order to both create and save the heatmap for each region, we must firstly establish where we'll save it\n",
    "    setwd(paste0(\"/home/aleixcanalda/Desktop/AleixCanalda/Heatmaps/\",chromosome,\"/\"))\n",
    "    #then we decide which type of document we'll be saving, an image in our case\n",
    "    png(file=(paste0(chromosome,\"region\",region,\"snppopeffect.png\")),width=1000, height=1000)\n",
    "    \n",
    "    #we can then create our heatmap using the grid tools which will allow us to join in one same picture two \n",
    "      #heatmaps(the effects of the snps and the ihs of the populations)\n",
    "    #inside viewport we decide where we want our heatmaps and determine their width and height\n",
    "    #inside Heatmap, we actually create the graph and determine how we want the heatmap to be and what to \n",
    "      #include/exclude\n",
    "    col_fun = colorRamp2(c(1, 10, 19), c(\"red\", \"orange\", \"white\"))\n",
    "    grid.newpage()\n",
    "    pushViewport(viewport(x = 0.005, y=1, width = 1.1, height= 0.25, just = c(\"left\", \"top\")))\n",
    "    ht_list = Heatmap(t(eff),cluster_rows = F,cluster_columns = F, col=col_fun, name=\"SNP effect\",row_names_gp =\n",
    "                      gpar(fontsize = 10))\n",
    "    draw(ht_list, newpage = FALSE)\n",
    "    popViewport()\n",
    "    \n",
    "    pushViewport(viewport(x = 0.005, y=0.6, width = 1.012, height = 0.5, just = c(\"left\", \"top\")))\n",
    "    ht_list = Heatmap(t(ihsmap), col=colorRamp2(c(-4, 0, 4), c(\"blue\", \"white\", \"red\")),cluster_rows = \n",
    "                      F,cluster_columns = F, name = \"Pop iHS\")\n",
    "    draw(ht_list, newpage = FALSE)\n",
    "    popViewport()\n",
    "    \n",
    "    dev.off()\n",
    "    \n",
    "    #here I present an example of how to create an interactive map , which may or may not be useful at some point\n",
    "    #library(\"d3heatmap\")\n",
    "    #d3heatmap(scale(t(ihsmap)),  main=\"iHS in Populations\", Rowv=NA,Colv=NA, cexRow=1, cexCol=1,\n",
    "    #          key = TRUE, keysize = 1,margins = c(25,15), trace=\"none\", lhei = c(5,20), lwid = c(2,10), \n",
    "      #col=bluered(20),\n",
    "    #          k_row = 4, # Number of groups in rows\n",
    "    #          k_col = 2) # Number of groups in columns\n",
    "    \n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result we would obtain would be something similar to:(heatmap example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the above has been done (which may take a while), in order to see which SNP has both a high adaptive significance (high iHS) and a high consequence/regulomescore, which means that that SNP has an important role, we should create new tables with which we can correlate these factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalconseqnumbertable$iHS <- NA\n",
    "transform(finalconseqnumbertable,'iHS' = as.numeric('iHS'))\n",
    "finalconseqnumbertable$iHSPop <- NA\n",
    "finalconseqnumbertable[, `iHSPop`:=as.double(`iHSPop`)]\n",
    "finalconseqnumbertable$iHSxRegulome <- NA\n",
    "transform(finalconseqnumbertable,'iHSxRegulome' = as.numeric('iHSxRegulome'))\n",
    "finalconseqnumbertable$iHSxConsequence <- NA\n",
    "transform(finalconseqnumbertable,'iHSxConsequence' = as.numeric('iHSxConsequence'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will go again chromosome for chromosome adding these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#firstly we must create the iHS and iHS with its population simultaneously\n",
    "for (c in 1:22) {\n",
    "  chromosome <- paste0(\"chr\",c)\n",
    "  print(paste(\"-->\", chromosome, sep=\" \"))\n",
    "  finalconseqchr <- finalconseqnumbertable %>% filter(Chromosome==c)\n",
    "    #we'll go through every population \n",
    "    for (popu in 1:length(populations)) {\n",
    "      print(paste(\"-->\", populations[popu], sep=\" \"))\n",
    "      #we'll get the file where we can find the iHS values\n",
    "      prova.chr.pop <- fread(paste0('/home/aleixcanalda/Desktop/AleixCanalda/ihs.output/', chromosome,'/',\n",
    "                                    chromosome, populations[popu],\".ihs.out.100bins.norm\"), header=T, sep=\"\\t\")\n",
    "      \n",
    "      #then we'll go snp for snp\n",
    "      for (snp in 1:nrow(finalconseqchr)) {\n",
    "        print(paste(\"--> snp \", snp, sep=\" \"))\n",
    "        #we get the exact position of our current snp\n",
    "        whatwhat <- unlist(finalconseqchr[snp,3])\n",
    "        #if our snp is found in the document with all the snps looking at the location, we continue, if not,\n",
    "          #we move on to the next snp\n",
    "        if (is.element((finalconseqchr[snp,\"Location\"]),prova.chr.pop$physicalPos)){\n",
    "          #if the snp written on the table so far is smaller than the one we're looking at now or IS NA, we\n",
    "            #save the new iHS value with its population\n",
    "          if ((abs(finalconseqnumbertable[finalconseqnumbertable$Chromosome==c & \n",
    "                                          finalconseqnumbertable$Location==whatwhat,\"iHS\"]) < \n",
    "               abs(unlist(prova.chr.pop[prova.chr.pop$physicalPos == whatwhat,\"standarizediHS\"])))\n",
    "               | is.na(finalconseqnumbertable[finalconseqnumbertable$Chromosome==c & \n",
    "                                              finalconseqnumbertable$Location==whatwhat,\"iHS\"])) {\n",
    "          finalconseqnumbertable[finalconseqnumbertable$Chromosome==c & finalconseqnumbertable$Location==whatwhat,19]\n",
    "              <- unlist(prova.chr.pop[prova.chr.pop$physicalPos == whatwhat,\"standarizediHS\"])\n",
    "          finalconseqnumbertable[finalconseqnumbertable$Chromosome==c & finalconseqnumbertable$Location==whatwhat,20] \n",
    "              <- populations[popu]\n",
    "          }\n",
    "          else {next}\n",
    "        }\n",
    "        \n",
    "        else {next}\n",
    "      }\n",
    "       \n",
    "    }\n",
    "}\n",
    "#after we have the iHS and iHSPop values, we fill the other two columns with the quocient mentioned beforehand\n",
    "for(yalla in 1:nrow(finalconseqnumbertable)) {\n",
    "  finalconseqnumbertable[yalla,21] <- (finalconseqnumbertable[yalla,18] / finalconseqnumbertable[yalla,19])\n",
    "  finalconseqnumbertable[yalla,22] <- (finalconseqnumbertable[yalla,17] / finalconseqnumbertable[yalla,19])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having created the new ordered table, we want to merge the table with the regions with the table with the snps so that we can associate them and order the regions using the snps to see which regions seem to be more important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalbigtable <- data.frame()\n",
    "for (c in 1:22) {\n",
    "  chromosome <- paste0(\"chr\",c)\n",
    "  print(paste(\"-->\", chromosome, sep=\" \"))\n",
    "  # We create a subset of all the regions in PHS of that chromosome\n",
    "  regions.per.chr <- bigtable %>% filter(chr==chromosome)\n",
    "  snp.per.chr <- finalconseqnumbertable %>% filter(Chromosome==c)\n",
    "  for (region in 1:nrow(regions.per.chr)) {\n",
    "    print(paste(\"--> region \", region, sep=\" \"))\n",
    "    for (snp in 1:nrow(snp.per.chr)) {\n",
    "      yey <- data.frame()\n",
    "      print(paste(\"-->\", snp, sep=\" \"))\n",
    "      if (snp.per.chr[snp,3]>regions.per.chr[region,5] & snp.per.chr[snp,3]<regions.per.chr[region,6]) {\n",
    "        yey <- rbind(yey,bigtable[605,])\n",
    "        yey <- cbind(yey,finalconseqnumbertable[26023,])\n",
    "        finalbigtable <- rbind(finalbigtable,yey)\n",
    "      }\n",
    "      else{next}\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
